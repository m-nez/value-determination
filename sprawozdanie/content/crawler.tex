\section{Uzyskiwanie danych}

Podstawowym zadaniem w big data jest uzyskiwaania danych do analizy, które najczęściej są otrzymywane przez crawler. Jest to program zbierający informacje o strukturze, stronach i treściach znajdujących się w internecie. Efekty pracy robota mogą być różne, w zależności od jego przeznaczenia, na przykład może on skanować wybrane witryny w celu zbudowania danych.

\subsection{Crawling w naszym projekcie}

W naszym przypadku robot chodził po stronie https://www.biznesradar.pl/ i pobierał z niej interesujące nas dane.
Wszystkie dane są zapisywane do pliku {INDEX}.csv w folderze raporty. Dane te otrzymujemy dla każdego kwartału, pomijając pięć pierwszych kwartałów od początku działalności.

\subsubsection{https://www.biznesradar.pl/raporty-finansowe-rachunek-zyskow-i-strat/ \{INDEX\},Q}
Z tej podstrony uzyskujemy następujące dane:
\begin{enumerate}
  \item Kwartał
  \item Przychody ze sprzedaży
  \item Techniczny koszt wytworzenia produkcji sprzedanej
  \item Koszty sprzedaży
  \item Koszty ogólnego zarządu
  \item Zysk ze sprzedaży
  \item Pozostałe przychody operacyjne
  \item Pozostałe koszty operacyjne
  \item Zysk operacyjny (EBIT)
  \item Przychody finansowe
  \item Koszty finansowe
  \item Pozostałe przychody (koszty)
  \item Zysk z działalności gospodarczej
  \item Wynik zdarzeń nadzwyczajnych
  \item Zysk przed opodatkowaniem
  \item Zysk (strata) netto z działalności zaniechanej
  \item Zysk netto
  \item Zysk netto akcjonariuszy jednostki dominującej
\end{enumerate}

\subsubsection{https://www.biznesradar.pl/wskazniki-wartosci-rynkowej/\{INDEX\},0}
\begin{enumerate}
\item Kurs
\item Ilość akcji
\end{enumerate}

\subsection{Etap filtracji danych}
Etap filtracji danych polegał na odrzuceniu pięciu pierwszych raportów kwartarnych dla każdej spółki.

\subsection{Wykorzystana technologia}
Crawler został napisany w języku C\# przy wykorzystaniu biblioteki HtmlAgilityPack.